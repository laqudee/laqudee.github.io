<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.38">
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html, body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme');
			const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
			if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
				document.documentElement.classList.toggle('dark', true);
			}
    </script>
    <title>机器学习、大数据、Python试题库 | Laqudee.Z - F2E</title><meta name="description" content="使用 Vuepress + Github Pages实现的博客">
    <link rel="modulepreload" href="/assets/app.3547d211.js"><link rel="modulepreload" href="/assets/2018-12-25-机器学习、大数据、Python题库.html.39b2c77d.js"><link rel="modulepreload" href="/assets/2018-12-25-机器学习、大数据、Python题库.html.7088fc7c.js">
    <link rel="stylesheet" href="/assets/style.a593710e.css">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/" class=""><img class="logo" src="/images/logo.jpg" alt="Laqudee.Z - F2E"><span class="site-name can-hide">Laqudee.Z - F2E</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide"><!--[--><div class="navbar-item"><a href="/" class="" aria-label="Home"><!--[--><!--]--> Home <!--[--><!--]--></a></div><div class="navbar-item"><a href="/articles/" class="router-link-active" aria-label="Articles"><!--[--><!--]--> Articles <!--[--><!--]--></a></div><div class="navbar-item"><a href="/projects/" class="" aria-label="Projects"><!--[--><!--]--> Projects <!--[--><!--]--></a></div><div class="navbar-item"><a href="/joyExperiment/" class="" aria-label="Joy"><!--[--><!--]--> Joy <!--[--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="More"><span class="title">More</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="More"><span class="title">More</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="external-link" href="https://github.com/ZhaoYLong" rel="noopener noreferrer" target="_blank" aria-label="Github"><!--[--><!--]--> Github <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a class="external-link" href="https://twitter.com/Laqudee1" rel="noopener noreferrer" target="_blank" aria-label="Twitter"><!--[--><!--]--> Twitter <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></li><!--]--></ul><!--]--></div></div><div class="navbar-item"><a class="external-link" href="https://github.com/ZhaoYLong/vuepress-starter" rel="noopener noreferrer" target="_blank" aria-label="GitHub"><!--[--><!--]--> GitHub <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><!--]--></nav><!--[--><!--]--><button class="toggle-dark-button" title="toggle dark mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items"><!--[--><div class="navbar-item"><a href="/" class="" aria-label="Home"><!--[--><!--]--> Home <!--[--><!--]--></a></div><div class="navbar-item"><a href="/articles/" class="router-link-active" aria-label="Articles"><!--[--><!--]--> Articles <!--[--><!--]--></a></div><div class="navbar-item"><a href="/projects/" class="" aria-label="Projects"><!--[--><!--]--> Projects <!--[--><!--]--></a></div><div class="navbar-item"><a href="/joyExperiment/" class="" aria-label="Joy"><!--[--><!--]--> Joy <!--[--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="More"><span class="title">More</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="More"><span class="title">More</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="external-link" href="https://github.com/ZhaoYLong" rel="noopener noreferrer" target="_blank" aria-label="Github"><!--[--><!--]--> Github <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a class="external-link" href="https://twitter.com/Laqudee1" rel="noopener noreferrer" target="_blank" aria-label="Twitter"><!--[--><!--]--> Twitter <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></li><!--]--></ul><!--]--></div></div><div class="navbar-item"><a class="external-link" href="https://github.com/ZhaoYLong/vuepress-starter" rel="noopener noreferrer" target="_blank" aria-label="GitHub"><!--[--><!--]--> GitHub <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading active collapsible">笔记 <span class="down arrow"></span></p><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a href="/articles/2018-08-25-D3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html" class="sidebar-item" aria-label="D3.js学习笔记"><!--[--><!--]--> D3.js学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2018-10-13-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E4%B9%8B%E9%9D%A2%E8%AF%95.html" class="sidebar-item" aria-label="操作系统基础知识之面试"><!--[--><!--]--> 操作系统基础知识之面试 <!--[--><!--]--></a><!----></li><li><a href="/articles/2018-11-24-Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html" class="sidebar-item" aria-label="Redis学习笔记"><!--[--><!--]--> Redis学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2018-12-01-Redis%E9%9D%A2%E8%AF%95.html" class="sidebar-item" aria-label="Redis之面试"><!--[--><!--]--> Redis之面试 <!--[--><!--]--></a><!----></li><li><a href="/articles/2018-12-11-MySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html" class="sidebar-item" aria-label="MySQL学习笔记"><!--[--><!--]--> MySQL学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2018-12-16-Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html" class="sidebar-item" aria-label="Java基础知识"><!--[--><!--]--> Java基础知识 <!--[--><!--]--></a><!----></li><li><a href="/articles/2018-12-18-Java%E9%9B%86%E5%90%88%E7%B1%BB%E5%AD%A6%E4%B9%A0.html" class="sidebar-item" aria-label="Java集合类学习"><!--[--><!--]--> Java集合类学习 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/articles/2018-12-25-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E5%A4%A7%E6%95%B0%E6%8D%AE%E3%80%81Python%E9%A2%98%E5%BA%93.html" class="router-link-active router-link-exact-active router-link-active sidebar-item active" aria-label="机器学习、大数据、Python试题库"><!--[--><!--]--> 机器学习、大数据、Python试题库 <!--[--><!--]--></a><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/articles/2018-12-25-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E5%A4%A7%E6%95%B0%E6%8D%AE%E3%80%81Python%E9%A2%98%E5%BA%93.html#python-ml-招聘基本要求" class="router-link-active router-link-exact-active sidebar-item" aria-label="（Python-ML）招聘基本要求："><!--[--><!--]--> （Python-ML）招聘基本要求： <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/articles/2018-12-25-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E5%A4%A7%E6%95%B0%E6%8D%AE%E3%80%81Python%E9%A2%98%E5%BA%93.html#应对策略-一切都是基于python" class="router-link-active router-link-exact-active sidebar-item" aria-label="应对策略：（一切都是基于Python）"><!--[--><!--]--> 应对策略：（一切都是基于Python） <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/articles/2018-12-25-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E5%A4%A7%E6%95%B0%E6%8D%AE%E3%80%81Python%E9%A2%98%E5%BA%93.html#bat大数据题库刷记录" class="router-link-active router-link-exact-active sidebar-item" aria-label="BAT大数据题库刷记录"><!--[--><!--]--> BAT大数据题库刷记录 <!--[--><!--]--></a><!----></li><!--]--></ul><!--]--></li><li><a href="/articles/2019-01-06-Java%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E6%A2%B3%E7%90%86.html" class="sidebar-item" aria-label="Java并发基础梳理"><!--[--><!--]--> Java并发基础梳理 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-01-08-Java%E5%B9%B6%E5%8F%91%E5%AD%A6%E4%B9%A0.html" class="sidebar-item" aria-label="Java并发学习"><!--[--><!--]--> Java并发学习 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-01-10-Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91.html" class="sidebar-item" aria-label="Java多线程与并发"><!--[--><!--]--> Java多线程与并发 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-01-17-Java%E9%9B%86%E5%90%88%E7%B1%BB%E6%80%BB%E7%BB%93.html" class="sidebar-item" aria-label="Java集合类总结"><!--[--><!--]--> Java集合类总结 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-02-03-Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6.html" class="sidebar-item" aria-label="Java内存模型与垃圾回收"><!--[--><!--]--> Java内存模型与垃圾回收 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-03-04-%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%81%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%AD%89%E6%8A%80%E6%9C%AF%E9%9D%A2%E8%AF%95.html" class="sidebar-item" aria-label="数据库、多线程等技术面试"><!--[--><!--]--> 数据库、多线程等技术面试 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-04-26-Hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0.html" class="sidebar-item" aria-label="Hadoop大数据处理入门"><!--[--><!--]--> Hadoop大数据处理入门 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-05-13-NLP%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6(Part.1).html" class="sidebar-item" aria-label="NLP算法研究，从入门到入坟"><!--[--><!--]--> NLP算法研究，从入门到入坟 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-05-23-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0.html" class="sidebar-item" aria-label="卷积神经网络简述"><!--[--><!--]--> 卷积神经网络简述 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-05-24-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html" class="sidebar-item" aria-label="神经网络简要介绍"><!--[--><!--]--> 神经网络简要介绍 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-06-12-SSM%E6%A1%86%E6%9E%B6%E5%8F%8ASpringBoot%E6%95%B4%E5%90%88%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html" class="sidebar-item" aria-label="SSM框架及Spring Boot整合学习"><!--[--><!--]--> SSM框架及Spring Boot整合学习 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-06-16-Vue%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86.html" class="sidebar-item" aria-label="Vue.js学习笔记之基础部分"><!--[--><!--]--> Vue.js学习笔记之基础部分 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-06-18-Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.html" class="sidebar-item" aria-label="设计模式学习笔记"><!--[--><!--]--> 设计模式学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-06-20-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F.html" class="sidebar-item" aria-label="设计模式学习笔记"><!--[--><!--]--> 设计模式学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-06-23-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%81%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE(Java).html" class="sidebar-item" aria-label="数据结构与算法分析回顾"><!--[--><!--]--> 数据结构与算法分析回顾 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-08-19-Front%20End%20And%20Idea.html" class="sidebar-item" aria-label="Front End And Idea"><!--[--><!--]--> Front End And Idea <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-09-16-%E6%B7%B1%E5%BA%A6%E7%90%86%E8%A7%A3DVA%E6%BA%90%E7%A0%81.html" class="sidebar-item" aria-label="深度理解DVA源码"><!--[--><!--]--> 深度理解DVA源码 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-09-17-roadhog%E8%A7%A3%E6%9E%90.html" class="sidebar-item" aria-label="roadhog简单解析"><!--[--><!--]--> roadhog简单解析 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-09-19-%E6%B7%B1%E5%BA%A6%E7%90%86%E8%A7%A3DVA%E6%BA%90%E7%A0%81.html" class="sidebar-item" aria-label="深度理解DVA源码"><!--[--><!--]--> 深度理解DVA源码 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-09-21-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0.html" class="sidebar-item" aria-label="卷积神经网络简述"><!--[--><!--]--> 卷积神经网络简述 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-09-21-%E7%A7%8B%E8%82%A5%E8%BF%B9.html" class="sidebar-item" aria-label="秋肥迹"><!--[--><!--]--> 秋肥迹 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-09-25-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0.html" class="sidebar-item" aria-label="卷积神经网络简述"><!--[--><!--]--> 卷积神经网络简述 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-09-26-Deep%20Learning%20Papers%20Reading%20Roadmap.html" class="sidebar-item" aria-label="Deep Learning Papers"><!--[--><!--]--> Deep Learning Papers <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-09-26-Learn%20Math%20Fast.html" class="sidebar-item" aria-label="Learn Math Fast"><!--[--><!--]--> Learn Math Fast <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-10-11-Redux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html" class="sidebar-item" aria-label="React通信利器--Redux"><!--[--><!--]--> React通信利器--Redux <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-10-12-dva%E6%A6%82%E5%BF%B5%E6%A2%B3%E7%90%86.html" class="sidebar-item" aria-label="DVA概念梳理[一遍通]"><!--[--><!--]--> DVA概念梳理[一遍通] <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-10-12-python%E6%89%B9%E9%87%8F%E5%A4%84%E7%90%86sphfile%E6%A0%BC%E5%BC%8F%E8%AF%AD%E9%9F%B3%E6%96%87%E4%BB%B6.html" class="sidebar-item" aria-label="Python &amp; Sphfile格式"><!--[--><!--]--> Python &amp; Sphfile格式 <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-10-21-%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%98%AF%E4%B8%AA%E4%BB%80%E4%B9%88%E9%BB%91%E9%AD%94%E6%B3%95.html" class="sidebar-item" aria-label="语音识别是个什么黑魔法？"><!--[--><!--]--> 语音识别是个什么黑魔法？ <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-10-9-ReduxSaga%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html" class="sidebar-item" aria-label="Redux-Saga是什么？"><!--[--><!--]--> Redux-Saga是什么？ <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-11-01-git%E6%8A%80%E8%83%BD%E5%A4%A7%E6%B3%95%E5%AD%A6%E4%B9%A0.html" class="sidebar-item" aria-label="Git技能学习笔记(第一篇)"><!--[--><!--]--> Git技能学习笔记(第一篇) <!--[--><!--]--></a><!----></li><li><a href="/articles/2019-12-29-%E6%9C%89%E8%B6%A3%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95.html" class="sidebar-item" aria-label="有趣的开源项目记录"><!--[--><!--]--> 有趣的开源项目记录 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-02-27-flutterNote.html" class="sidebar-item" aria-label="Flutter学习笔记"><!--[--><!--]--> Flutter学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-03-01-flutterNote02.html" class="sidebar-item" aria-label="Flutter学习笔记"><!--[--><!--]--> Flutter学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-05-24-nodeJS%E5%AD%A6%E4%B9%A0%E4%BA%8C.html" class="sidebar-item" aria-label="node学习笔记"><!--[--><!--]--> node学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-05-24-nodeJS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html" class="sidebar-item" aria-label="node学习笔记"><!--[--><!--]--> node学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-05-27-nodejs%E5%AD%A6%E4%B9%A0%E4%B8%89.html" class="sidebar-item" aria-label="node学习笔记"><!--[--><!--]--> node学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-05-29-nodeJS%E5%9B%9B.html" class="sidebar-item" aria-label="node学习笔记"><!--[--><!--]--> node学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-06-02-nodeJS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%94.html" class="sidebar-item" aria-label="node学习笔记"><!--[--><!--]--> node学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-06-07-nodeJS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%AD.html" class="sidebar-item" aria-label="node学习笔记"><!--[--><!--]--> node学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-06-28-flutterNote03.html" class="sidebar-item" aria-label="Flutter学习笔记"><!--[--><!--]--> Flutter学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-07-01-flutterNote04.html" class="sidebar-item" aria-label="Flutter学习笔记"><!--[--><!--]--> Flutter学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-07-02-flutterNote05.html" class="sidebar-item" aria-label="Flutter学习笔记"><!--[--><!--]--> Flutter学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-07-07-flutterNote06.html" class="sidebar-item" aria-label="Flutter学习笔记"><!--[--><!--]--> Flutter学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-07-13-flutterNote07.html" class="sidebar-item" aria-label="Flutter学习笔记"><!--[--><!--]--> Flutter学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-07-14-flutterNote08.html" class="sidebar-item" aria-label="Flutter学习笔记"><!--[--><!--]--> Flutter学习笔记 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-12-03-CLI%E6%9C%8D%E5%8A%A1.html" class="sidebar-item" aria-label="Vue-Cli Think"><!--[--><!--]--> Vue-Cli Think <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-12-03-preset.html" class="sidebar-item" aria-label="Vue-Cli Think"><!--[--><!--]--> Vue-Cli Think <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-12-03-%E6%B5%8F%E8%A7%88%E5%99%A8%E5%85%BC%E5%AE%B9.html" class="sidebar-item" aria-label="Vue-Cli Think"><!--[--><!--]--> Vue-Cli Think <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-12-04-CSS%E7%9B%B8%E5%85%B3.html" class="sidebar-item" aria-label="Vue-Cli Think"><!--[--><!--]--> Vue-Cli Think <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-12-04-webpack%E7%9B%B8%E5%85%B3.html" class="sidebar-item" aria-label="Vue-Cli Think"><!--[--><!--]--> Vue-Cli Think <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-12-04-%E6%9E%84%E5%BB%BA%E7%9B%AE%E6%A0%87.html" class="sidebar-item" aria-label="Vue-Cli Think"><!--[--><!--]--> Vue-Cli Think <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-12-04-%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%92%8C%E6%A8%A1%E5%BC%8F.html" class="sidebar-item" aria-label="Vue-Cli Think"><!--[--><!--]--> Vue-Cli Think <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-12-04-%E9%83%A8%E7%BD%B2.html" class="sidebar-item" aria-label="Vue-Cli Think"><!--[--><!--]--> Vue-Cli Think <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-12-26-Vue2%E5%92%8CEcharts%E7%9A%84%E5%A5%87%E5%A6%99%E5%8F%8D%E5%BA%94.html" class="sidebar-item" aria-label="Vue2和Echarts的奇妙反应"><!--[--><!--]--> Vue2和Echarts的奇妙反应 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-12-26-Vue2%E5%92%8CHightCharts.html" class="sidebar-item" aria-label="Vue2和HighCharts的奇妙反应"><!--[--><!--]--> Vue2和HighCharts的奇妙反应 <!--[--><!--]--></a><!----></li><li><a href="/articles/2020-12-29-Vue3%E7%BB%84%E5%90%88%E5%BC%8FAPI%E6%84%8F%E8%A7%81%E7%A8%BF.html" class="sidebar-item" aria-label="Vue3组合式API意见稿"><!--[--><!--]--> Vue3组合式API意见稿 <!--[--><!--]--></a><!----></li><li><a href="/articles/2021-01-18-webpack%E7%AC%94%E8%AE%B0.html" class="sidebar-item" aria-label="webpack课程记录"><!--[--><!--]--> webpack课程记录 <!--[--><!--]--></a><!----></li><li><a href="/articles/2021-01-18-%E7%81%B5%E5%85%89%E4%B9%8D%E7%8E%B0.html" class="sidebar-item" aria-label="Front End And Idea"><!--[--><!--]--> Front End And Idea <!--[--><!--]--></a><!----></li><li><a href="/articles/" class="router-link-active sidebar-item" aria-label="如何使用vuePress"><!--[--><!--]--> 如何使用vuePress <!--[--><!--]--></a><!----></li><!--]--></ul><!--]--></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><h3 id="python-ml-招聘基本要求" tabindex="-1"><a class="header-anchor" href="#python-ml-招聘基本要求" aria-hidden="true">#</a> （Python-ML）招聘基本要求：</h3><ul><li>1、数据库Mysql及web框架Django</li><li>2、Python数据分析</li><li>3、Python的科学计算库、机器学习库等</li><li>4、基于Python的数据结构和算法研究</li><li>5、各种机器学习算法</li></ul><h3 id="应对策略-一切都是基于python" tabindex="-1"><a class="header-anchor" href="#应对策略-一切都是基于python" aria-hidden="true">#</a> 应对策略：（一切都是基于Python）</h3><ul><li>1、刷BAT的大数据（机器学习、深度学习）笔/面试题</li><li>2、加深对数据处理分析的流程熟悉，编写数据处理/分析流程及必要的手段</li><li>3、增强深度学习的系统性学习（轮廓）</li><li>4、使用Python的web框架Django，来构造一个真正的web项目（现成的），另外加深对Django特性的了解</li><li>5、在数据处理方面一定要有亮点如对CNN的理解和实践、对SVM的了解和实战项目</li><li>6、<em>不可三心二意，一心一意铺在数据分析和Python上</em></li><li>7、最后分门别类编写对应的心得和技术亮点（新点）</li><li>8、加强对英语的学习，提升听说能力（important）</li><li>9、基础的数据结构回顾，必要时可刷leatcode题库</li></ul><h3 id="bat大数据题库刷记录" tabindex="-1"><a class="header-anchor" href="#bat大数据题库刷记录" aria-hidden="true">#</a> BAT大数据题库刷记录</h3><ul><li><p><a href="https://blog.csdn.net/sinat_35512245/article/details/78796328" target="_blank" rel="noopener noreferrer">学习地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></li><li><p>1、请简要介绍SVM</p><ul><li>SVM，全称support vector machine, 中文称之为支撑向量机。是一种面向数据的分类算法，它的目标是为了确定一个分类超平面，从而将数据分开。</li><li>扩展：SVM从简单到繁琐：线性可分SVM（硬隔离）、线性支持向量机（软隔离）、非线性SVM（核函数）。PS：了解什么是硬间隔、软间隔</li></ul></li><li><p>2、请简要介绍Tensorflow的计算图</p><ul><li>Tensorflow是一个通过计算图的形式来表述计算的编程过程，计算图也叫数据流图，可以把计算图看成一种有向图，Tensorflow中的每一个计算都是计算图上的节点，而节点之间的边描述计算之间的依赖关系。</li><li>Tensorflow的“计算图”分为2部分 <ul><li>构造部分，包含计算流图</li><li>执行部分，通过session来执行图中的计算</li></ul></li></ul></li><li><p>3、请问GBDT和XGBoost的区别是什么？</p><ul><li>PS：我不知道这是做什么的-_-<a href="https://xijunlee.github.io/2017/06/03/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/" target="_blank" rel="noopener noreferrer">学习地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li><p>4、在K-means或KNN，我们使用欧氏距离来计算最近的邻居之间的距离。为什么不用曼哈顿距离？</p><ul><li>曼哈顿距离只计算水平或垂直距离，有维度限制。另一方面，欧氏距离可用于任何空间的距离计算。因为数据可以存在于任何空间，欧氏距离是更行的选择。例如：国际象棋棋盘使用曼哈顿距离计算，因为它们的在各自的水平和垂直方向做的运动。</li></ul></li><li><p>5、百度2015机器学习笔试题<a href="http://www.itmian4.com/thread-7042-1-1.html" target="_blank" rel="noopener noreferrer">链接<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></li><li><p>6、简单说说特征工程。</p><ul><li>互联网公司的数据挖掘工程师工作内容？ <ul><li>研究各种算法，设计高大上模型...</li><li>深度学习的应用，N层神经网络...</li></ul></li><li>大部分复杂模型的算法都是数据科学家在做，大部分同学都是在跑数据、各种map-reduce、hive SQL、数据仓库搬砖、数据清洗、分析业务、找特征LR打天下 <ul><li>关于LR（逻辑回归）。把LR从头到脚讲一遍。建模，现场数学推导，每种解法原理，正则化、LR和maxent模型之间的关系，LR为啥比线性回归好？<a href="http://blog.csdn.net/sinat_35512245/article/details/54881672" target="_blank" rel="noopener noreferrer">学习链接<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li></ul></li><li><p>7、overfitting怎么解决？</p><ul><li>dropout、正则化（regularization）、batch normalization</li></ul></li><li><p>8、 LR和SVM的关系？<a href="http://blog.csdn.net/timcompp/article/details/62237986" target="_blank" rel="noopener noreferrer">学习链接<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><ul><li>关系： <ul><li>1、LR和SVM都是用来处理分类问题，一般都用来处理线性二分问题</li><li>2、两个方法都可以增加不同的正则化项，如L1、L2等等。所以实验中，两种算法结果很接近</li></ul></li><li>区别： <ul><li>1、LR是参数模型，SVM是非参数模型。</li><li>2、从目标函数来看，区别在于LR采用logistical loss，SVM采用的是hinge loss。这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。</li><li>3、SVM的处理方法是只考虑support vectors，LR通过非线性映射，大大减少了离分类平面远的点的权重，提升了与分类最相关的数据点的权重。</li><li>4、逻辑回归相对来说模型更简单，好理解，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些，SVM转化为对偶问题后,分类只需要计算与少数几个支持向量的距离,这个在进行复杂核函数计算时优势很明显,能够大大简化模型和计算。</li><li>5、logic能做的SVM能做，但在准确率上，SVM可以做logic不能做的。</li></ul></li></ul></li><li><p>9、LR和线性回归的区别与联系？</p><ul><li>1、二者首先都是广义的线性回归</li><li>2、经典线性模型的优化目标函数是最小二乘，LR则是似然函数</li><li>3、另外线性回归在整个实数域范围内进行预测，敏感度一致，而分类范围，需要在[0,1]。逻辑回归就是一种减小预测范围，将预测值限定为[0,1]间的一种回归模型，因而对于这类问题来说，逻辑回归的鲁棒性比线性回归的要好。</li><li>4、逻辑回归本质是一个线性回归模型，逻辑回归是以线性回归为理论支持的。但线性回归模型无法做到sigmoid的非线性形式，sigmoid可以轻松处理0/1分类问题。</li></ul></li><li><p>10、谈谈判别式模型和生成式模型？</p><ul><li>判别方法：由数据直接学习决策函数 Y = f(X)，或者由条件分布概率P(Y|X)作为预测模型，即判别模型。</li><li>生成方法：由数据学习联合概率密度分布函数P(Y|X)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型。</li><li>由生成模型可以得到判别模型，但由判别模型得不到生成模型。</li><li>常见的判别模型：K近邻、SVM、决策树、感知机、线性判别分析（LDA）、线性回归、传统的神经网络、逻辑斯蒂回归、boostling、条件随机场。</li><li>常见的生成模型：朴素贝叶斯、隐马尔可夫模型、高斯混合模型、文档主题生成模型（LDA）、限制波尔兹曼机。</li></ul></li><li><p>11、L1和L2的区别</p><ul><li>L1范数（L1 norm）是指向量中各元素绝对值之和，也有个美称“稀疏规则算子”。</li><li>L2范数为一个向量中各个元素平方和的1/2次方，L2范数又被称为Euclidean范数或Frobenius范数</li><li>Lp范数为X向量中各元素绝对值p次方和的1/p次方。</li><li>在支持向量机学习过程中，L1范数实际是一种对于成本函数求解最优的过程，因此，L1范数正则化通过向成本函数中添加L1范数，使得学习得到的结果满足稀疏化，从而方便人类提取特征。</li><li>L1范数可以使权值稀疏，方便特征提取。</li><li>L2范数可以防止过拟合，提升模型的泛化能力。</li></ul></li><li><p>12、L1和L2正则先验分别服从什么分布？</p><ul><li>L1服从拉普拉斯分布，L2服从高斯分布</li></ul></li><li><p>13、CNN最成功的应用是在CV，那为什么NLP和Speech的很多问题也可以用CNN解出来？为什么AlphaGo里也用了CNN？这几个不相关的问题的相似性在哪里？CNN通过什么手段抓住了这个共性？</p><ul><li><a href="https://zhuanlan.zhihu.com/p/25005808" target="_blank" rel="noopener noreferrer">答案地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li><p>14、为什么朴素贝叶斯如此“朴素”？</p><ul><li>因为它假定所有的特征在数据集中的作用是同样重要和独立的。正如我们所知，这个假设在现实世界中很不真实，因此，说朴素贝叶斯真的很“朴素”。</li></ul></li><li><p>15、Machine Learning中为何经常对数据做归一化？</p><ul><li>1）归一化后加快梯度下降求最优解的速度；</li><li>2）归一化后有可能提高精度。<a href="http://www.cnblogs.com/LBSer/p/4440590.html" target="_blank" rel="noopener noreferrer">学习链接<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li><p>16、谈谈深度学习中的归一化问题？ <a href="http://www.julyedu.com/video/play/69/686" target="_blank" rel="noopener noreferrer">答案参考地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></li><li><p>17、简要说说一个完整ML项目流程。</p><ul><li>1）抽象成数学问题 <ul><li>明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的工作，胡乱尝试成本很高。这里的抽象成数学问题，指的我们明确我们可以获得什么样的数据，目标是一个分类还是回归或者是聚类的问题。</li></ul></li><li>2）获取数据 <ul><li>数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限；数据要有代表性，否则必然会过拟合。</li><li>而且对于分类问题，数据偏斜不能过于严重，不同类别的数据数量不要有数个数量级的差距。</li><li>而且还要对数据的量级有一个评估，多少个样本，多少个特征，可以估算出其对内存的消耗程度，判断训练过程中内存是否能够放得下。如果放不下就得考虑改进算法或者使用一些降维的技巧了。如果数据量实在太大，那就要考虑分布式了。</li></ul></li><li>3）特征预处理与特征选择 <ul><li>良好的数据只有能够提取出良好的特征才能真正发挥效力</li><li>特征预处理、数据清洗是关键的步骤，往往能够使得算法的效果和性能得到明星提高。归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们身上。这些工作简单可复制，收益稳定可预期，是机器学习的基础必备步骤。</li><li>筛选出显著特征、摒弃非显性特征，需要ML工程师反复理解业务。这对很多结果有决定性的影响。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。</li></ul></li><li>4）训练模型与调优 <ul><li>直到这一步才用到我们上面说的算法进行训练。现在很多算法都能够封装成黑盒供人使用。但是真正考验水平的是调整这些算法的（超）参数，使得结果变得更加优秀。这需要我们对算法的原理有深入的理解。理解越深，就越能发现问题的症结，提出良好的调优方案。</li></ul></li><li>5）模型诊断 <ul><li>如何确定模型调优的方向与思路？这需要对模型进行诊断的技术。</li><li>过拟合、欠拟合判断是模型诊断中至关重要的的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。</li><li>误差分析也是ML至关重要的步骤。通过观察误差样本，全面分析误差产生的原因：是参数问题还是算法选择问题，是特征的问题还是数据本身的问题...</li><li>诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试，进而达到最优状态。</li></ul></li><li>6）模型融合 <ul><li>一般来说，模型融合能使得效果有一定提升，而且效果很好。</li><li>工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。</li></ul></li><li>7）上线运行 <ul><li>这一部分内容主要跟工程实现的相关性比较大。工程上是结果导向，模型在线运行的效果直接决定模型的成败。不单纯包括其准确程度、误差等情况，还包括其运行的速度（时间复杂度）、资源消耗程度（空间复杂度）、稳定是否可接受。</li></ul></li><li>这些流程主要是工程实践上总结出的一些经验，并不是每个项目都包含完整的一个流程。</li></ul></li><li><p>18、new和malloc的区别？</p><ul><li>malloc()函数全称memory allocation，中文叫动态内存分配。<a href="https://www.cnblogs.com/fly1988happy/archive/2012/04/26/2470542.html" target="_blank" rel="noopener noreferrer">学习链接<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li><p>19、hash冲突及解决办法？</p><ul><li>1）开放定址法</li><li>2）再哈希法；同时构造多个不同的哈希函数</li><li>3）链地址法：适合于经常进行插入和删除的情况</li><li>4）建立公共溢出区：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表</li></ul></li><li><p>20、如何解决梯度消失和梯度膨胀？</p><ul><li>（1）梯度消失： <ul><li>根据链式法则，如果每一层神经元对上一层的输出的偏导乘上权重结果都小于1的话，那么即使这个结果是0.99，在经过足够多层传播之后，误差对输入层的偏导会趋于0。</li><li>可以采用ReLU激活函数有效的解决梯度消失的情况。</li></ul></li><li>（2）梯度膨胀： <ul><li>根据链式法则，如果每一层神经元对上一层的输出的偏导乘上权重结果都大于1的话，在经过足够多层传播之后，误差对输入层的偏导会趋于无穷大。</li></ul></li></ul></li><li><p>21、简单说下有监督学习和无监督学习的区别？</p><ul><li>有监督学习：对具有标记的训练样本进行学习，以尽可能对训练样本集外的数据进行分类预测。（LR、SVM、BP、RF、GBDT）</li><li>无监督学习：对未标记的样本进行训练学习，比如发现这样样本中的结构知识。（K-means,DL）</li></ul></li><li><p>22、了解正则化？</p><ul><li>正则化是针对过拟合而提出的，以为在求解模型最优的是一般优化最小的经验风险，现在在该经验风险上加入模型复杂度这一项（正则化项是模型参数向量的范数），并使用一个rate比率来权衡模型复杂度与以往经验风险的权重，如果模型复杂度越高，结构化的经验风险越大，现在的目标就变为了结构经验风险的最优化，可以防止模型训练过度复杂，有效的降低过拟合的风险。</li><li>奥卡姆剃刀原理，能很好的解释已知数据并且十分简单才是最好的模型。</li></ul></li><li><p>23、协方差和相关性有什么区别？</p><ul><li>相关性是协方差的标准格式。协方差本身很难比较。因为不同的变量有不同的度量方式，我们通过计算相关性来得到一个介于-1和1之间的值，这就忽略它们各自不同的度量。</li></ul></li><li><p>24、线性分类器与非线性分类器的区别以及优劣？</p><ul><li>若模型是参数的线性函数，并且存在线性分类面，那么就是线性分类器，否则不是。</li><li>常见线性分类器：LR、贝叶斯分类、单层感知机、线性回归。</li><li>常见的非线性分类器：决策树、RF、GBDT、多层感知机。</li><li>SVM两种都有（线性核还是非线性核：如高斯核）</li><li>线性分类器速度快、编程方便，但可能拟合效果不好。</li><li>非线性分类器编程复杂，但效果拟合能力强。</li></ul></li><li><p>25、数据的逻辑存储结构（如数组、队列、树、栈等）对于软件开发具有十分重要的影响，试从运行速度、存储效率、适用场景简要分析？</p></li><li><p>26、什么是分布式数据库？</p><ul><li>是在集中式数据库系统成熟技术的基础上发展起来的，但不是简单地把集中式数据库分散地实现，它具有自己的性质和特征。集中式数据库系统的许多概念和技术，如数据独立性、数据共享和减少冗余度、并发控制、完整性、安全性和恢复等在分布式数据库系统中都有不同的、更加丰富的内容。</li></ul></li><li><p>27\简单说说贝叶斯定理？</p><ul><li>条件概率（后验概率）就是事件A在另一个事件B已经发生条件下的发生概率。P(A|B), P(A|B)=P(A交B)/P(B)</li><li>联合概率：两个事件同时发生的概率。</li><li>边缘（际）概率：（又称先验概率）：A事件的边缘概率表示为P(A)</li><li>考虑一个问题：P(A|B)是在B发生情况下A发生的可能行？ <ul><li>P(A|B) = P(B|A)P(A) / P(B)</li></ul></li></ul></li><li><p>28、简单说下sigmoid激活函数</p><ul><li>常用的非线性激活函数有sigmoid、tanh、relu等等，前两者比较常见于全连接层，后者常见于卷积层。</li></ul></li><li><p>29、什么是卷积？</p><ul><li>对于图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重：因为每个神经元的多个权重固定，所以又可以看做一个恒定的滤波器filter）做内积（逐各元素相乘在求和）的操作就是所谓的「卷积」操作，也是卷积神经网络的名字来源。</li></ul></li><li><p>30、什么是CNN的池化pool层？</p><ul><li>池化，简而言之，即取平均或最大，如：</li><li>[1 1 2 4] --&gt; [6 8]</li><li>[5 6 7 8]</li></ul></li><li><p>31、简述什么是生成对抗网络？</p><ul><li>GAN之所以是对抗的，是因为GAN的内部是竞争关系，一方叫generator（生成模型），它的主要工作是生成图片，并且尽量使得其看上去是来自于训练样本的。另一方是discriminator（判断模型），其目标是判断输入图片是否属于真实训练样本。</li></ul></li><li><p>32、哪些机器算法不需要做归一化处理？</p><ul><li>概率模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率，如决策树、RF。而像Adaboost、GBDT、XGBoost、SVM、LR、KNN、KMeans之类的最优问题需要归一化。</li></ul></li><li><p>33、说说梯度下降</p><ul><li><a href="http://www.cnblogs.com/LeftNotEasy/archive/2010/12/05/mathmatic_in_machine_learning_1_regression_and_gradient_descent.html" target="_blank" rel="noopener noreferrer">学习地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li><p>34、梯度下降法找到的一定是下降最快的方向？</p><ul><li>并不一定是下降最快的方向，它只是目标函数在当前的点的切平面上下降最快的方向。</li></ul></li><li><p>35、说说随机梯度下降法的问题和挑战？</p><ul><li>困难： <ul><li>1）梯度的计算</li><li>2）学习率的选择，学习率太小，导致算法收敛太慢，学习率选择过大容易导致算法不收敛。</li></ul></li></ul></li><li><p>36、什么是最小二乘法？</p><ul><li>最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。</li></ul></li><li><p>37、说说Python到底是什么样的语言？<a href="http://nooverfit.com/wp/15%E4%B8%AA%E9%87%8D%E8%A6%81python%E9%9D%A2%E8%AF%95%E9%A2%98-%E6%B5%8B%E6%B5%8B%E4%BD%A0%E9%80%82%E4%B8%8D%E9%80%82%E5%90%88%E5%81%9Apython%EF%BC%9F/" target="_blank" rel="noopener noreferrer">答案解析<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><ul><li>Python是解释型语言，Python运行前不需要编译。</li><li>Python是动态的，不需要在声明变量时指定类型。</li><li>面向对象，允许定义类并可以继承和组合，Python没有访问标识符，如C++中的private、public</li><li>Python中函数是一等公民，它们可以被直接赋值，从其他函数返回值，并传递函数对象，类不是一等公民。</li><li>Python代码很快，但跑起来会比编译型语言慢，但Python允许使用C扩展写程序，所以瓶颈可以处理。</li><li>Python的应用场景很多，web开发，自动化，科学建模，大数据应用等。它也经常被视为胶水语言。</li><li>Python可以简化工作，使得程序员能过关心如何重写代码而不是详细的看一遍底层实现</li></ul></li><li><p>38、Python和多线程。是不是个好主意？列举你觉得可以让Python代码并行运行的方法？</p><ul><li>Python实际上不允许多线程。它有一个threading包但是如果你想加快代码运行速度，或者想并行运行，这不是一个好主意。Python有一个机制叫全局解释器锁（GIL）。GIL保证每次只有一个线程在解释器中跑。一个线程获得GIL，之后再交给下一个线程。所以，看起来是多个线程在同时跑，但是实际上每个时刻只有CPU核在跑一个线程，没有真正利用多个CPU核跑多个线程。就是说，多个线程在抢着跑一个CPU核。</li><li>但是还是有使用threading包的情况的。比如你真的想跑一个可以线程间抢占的程序，看起来是并行的。或者有很长时间的IO等待线程，这个包就会有用。但是threading包不会使用多核去跑代码。</li><li>真正的多核多线程可以通过多进程，一些外部库如Spark和Hadoop，或者用Python代码去调用C方法等等来实现。</li></ul></li><li><p>39、怎么对你的代码进行跟踪、协同写代码？</p><ul><li>版本号控制！只是关键，你应该很高兴地告诉他们你怎么使用git的，当然svn也是。</li></ul></li><li><p>40、 修饰器的概念？</p></li><li><p>41、Python的垃圾回收机制？</p><ul><li>Python在内存中维护对象的引用次数。如果一个对象的引用次数变为0，垃圾回收机制会回收这个对象作为他用。</li><li>有时候会有“引用循环”的事情发生。垃圾回收器定期检查回收内存。一个例子是，如果你有两个对象 o1 和 o2，并且o1.x == o2 and o2.x == o1. 如果 o1 和 o2 都没有被其他对象使用，那么它们都不应该存在。但是它们的应用次数都是1，垃圾回收不会起作用。</li><li>一些启发算法可以用来加速垃圾回收。比如，最近创建的对象更可能是无用的。用创建时间来度量对象的生命时长，生命越长，越可能是更有用的对象。</li></ul></li><li><p>42、其他Python面试题</p><ul><li><a href="http://www.cnblogs.com/tom-gao/p/6645859.html" target="_blank" rel="noopener noreferrer">学习连接<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li><p>43、请写出一段Python代码实现删除一个list里面的重复元素。</p><ul><li>要求：使用set函数，set(list);使用字典函数；</li></ul></li></ul><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>
b <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
b <span class="token operator">=</span> b<span class="token punctuation">.</span>fromkeys<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
c <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
c
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><ul><li>44、编程用sort进行排序，然后从最后一个元素开始判断。</li></ul><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span>
a<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span>
last<span class="token operator">=</span>a<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> last<span class="token operator">==</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token keyword">del</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span> last<span class="token operator">=</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><ul><li>45、Python里面如何生成随机数？ <ul><li>random模块 <ul><li>随机整数：random.randint(a,b):返回随机整数x, a&lt;=x&lt;=b</li><li>random.randrange(start,stop,[step])</li><li>随机实数：random.random()：返回（0，1）之间的浮点数</li><li>random.uniform(a,b)：返回指定范围内的浮点数</li></ul></li></ul></li><li>46、说说常见的损失函数 <ul><li>对于给定的输入X,由f(X)输出相应的Y，这个输出的预测值f(X)与真实的Y可能一致，也可能不一致（误差在所难免），用一个损失函数来度量预测错误的程度，这个损失函数记住L(Y, f(x))</li><li>常用的损失函数有： <ul><li>0-1损失函数</li><li>平方损失函数</li><li>对数损失函数</li></ul></li></ul></li><li>47、简单介绍逻辑回归LR <ul><li>目的：从特征学习出一个0/1分类模型，而这个模型是将特性的线性组合作为自变量，由于自变量的取值范围是负无穷到正无穷。因此使用LR函数（或称为sigmoid函数）将自变量映射到（0，1）上，映射后的值被认为是属于y=1的概率。</li></ul></li><li>48、以下哪些方法不可以直接对文本分类 <ul><li>决策树、SVM、KNN都可以直接对文本分类；但Kmeans不行，Kmeans是聚类方法，无监督学习</li></ul></li><li>49、Kmeans的复杂度？ <ul><li>时间复杂度：O(tKmn)，其中，t为迭代次数，K为簇的数目，m为记录数，n为维数</li><li>空间复杂度：O((m+K)n)</li></ul></li><li>50、影响聚类算法结果的主要因素有 <ul><li>分类标准、特征选择、模式相似性测度</li></ul></li><li>51、 <ul><li>（1）模式识别中，马氏距离较之欧氏距离的优点：尺度不变形、考虑模式的分布</li><li>（2）影响基本K均值算法的主要因素：样本输入顺序、模式相似性测度、聚类准则</li><li>（3）在统计模式分类问题中，当先验概率未知时，可以使用 「最小最大损失准则」、「N-P判决」</li><li>（4）欧氏距离具有「平移不变性」「旋转不变性」</li><li>（5）马氏距离具有「尺度缩放不变性」「不受量纲影响的特性」「平移不变性」「旋转不变性」</li></ul></li><li>52、你有哪些DL（RNN、CNN）调参经验？ <ul><li><a href="https://www.zhihu.com/question/41631631" target="_blank" rel="noopener noreferrer">学习地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li>53、说说RNN（循环神经网络）原理 <ul><li><a href="http://blog.csdn.net/heyongluoyao8/article/details/48636251" target="_blank" rel="noopener noreferrer">相关题目1<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://zhuanlan.zhihu.com/p/28054589" target="_blank" rel="noopener noreferrer">相关题目2<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li>54、当机器学习性能遭遇瓶颈时，如何优化？ <ul><li>可以从4个方面进行尝试：基于数据、借助算法、用算法调参、借助模型融合。谈多谈少看经验和心得。</li><li><a href="http://blog.csdn.net/han_xiaoyang/article/details/53453145" target="_blank" rel="noopener noreferrer">机器学习改善备忘录<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li>55、做过什么样的机器学习项目？比如如何从零构建一个推荐系统？ <ul><li>看个人项目了，所以说还是要有实战的经验。「数据分析项目」</li></ul></li><li>56、数据预处理 <ul><li>（1）缺失值，填充缺失值fillna： <ul><li>1）离散：None</li><li>2）连续：均值</li><li>3）缺失值太多，则直接去除该列</li></ul></li><li>（2）连续值：离散化。有的模型（如决策树）需要离散化</li><li>（3）对定量特征二值化。核心在于设定一个阈值，大于阈值设置为1，小于等于阈值赋值为0.</li><li>（4）皮尔逊相关系数，去除高度相关的列</li></ul></li><li>57、如何进行特征选择？ <ul><li>特征选择是一个重要的数据预处理过程，主要有两个原因： <ul><li>一是减少特征数量、降维，使模型泛化能力更强，减少过拟合;</li><li>二是增强对特征和特征值之间的理解。</li></ul></li><li>常用的特征选择方式： <ul><li>去除方差较小的特征</li><li>正则化。L1正则化能够生成稀疏的模型。L2正则化的表现更加稳定，由于有用的特征往往对应的系数飞零。</li><li>随机森林，对于分类问题，通常采用基尼不纯度或者信息增益，对于回归问题，通常采用的是方差或者最小二乘拟合。一般不需要feature engineering、调参等繁琐的步骤。它的两个主要问题，1是重要的特征有可能得分很低（关联特征问题），2是这种方法对特征变量类别多的特征越有利（偏向问题）。</li><li>稳定性选择。是一种基于二次抽样和选择算法相结合较新的方法，选择算法可以是回归、SVM或其他类似的方法。它的主要思想是在不同的数据子集和特征子集上运行特征选择算法，不断的重复，最终汇总特征选择结果，比如可以统计某个特征被认为是重要特征的频率（被选为重要特征的次数除以它所在的子集被测试的次数）。理想情况下，重要特征的得分会接近100%。稍微弱一点的特征得分会是非0的数，而最无用的特征得分将会接近于0。</li></ul></li></ul></li><li>58、你知道有哪些数据处理和特征工程的处理？ <img src="https://img-blog.csdn.net/20171214121831941?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzU1MTIyNDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="特征工程"></li><li>59、SVD和PCA <ul><li>PCA的理念是使得数据投影后的方差最大，找到这样一个投影，满足方差最大的条件即可。而经过去除均值的操作后，就可以使用SVD分解来求解这样的一个投影向量，选择特征最大的方向。</li></ul></li><li>60、数据不平衡问题？ <ul><li>这主要是由数据的分布不平衡造成的，解决方案如下： <ul><li>1）采样，对小样本加噪声采样，对大样本进行下采样</li><li>2）进行特殊的加权，如在Adaboost中或者SVM中</li><li>3）采用对不平衡数据集不敏感的算法</li><li>4）改变评价标准：用AUC/ROC来进行评价</li><li>5）采用Bagging/Boosting/Ensemble等方法</li><li>6）考虑数据的先验分布</li></ul></li></ul></li><li>61、简述神经网络的发展 <ul><li>MP模型+sgn——&gt;单层感知机（只能线性）+sgn——&gt;Minsky 低谷 ——&gt;多层感知机+BP+Sigmoid——&gt;(低谷) ——&gt;深度学习+Pretraining+ReLU/Sigmoid</li></ul></li><li>62、深度学习常用方法 <ul><li><a href="http://blog.csdn.net/u010496169/article/details/73550487" target="_blank" rel="noopener noreferrer">参考地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li>63、卷积神经网络可以对一个输入进行多种变换（旋转、平移、缩放），这表示正确吗？ <ul><li>把数据传入神经网络之前需要做一系列的数据预处理（也就是旋转、平移、缩放）工作，神经网络本身不能完成这些变换。</li></ul></li><li>64、常见的监督学习算法有哪些？ <ul><li>感知机、SVM、人工神经网络、决策树、逻辑回归</li></ul></li><li>65、数据清理中，处理缺失值的方法？ <ul><li>估算、整例删除、变量删除、成对删除</li></ul></li><li>66、试推导样本空间中任意点x到超平面（w，b）的距离公式 <img src="https://img-blog.csdn.net/20171214141457046?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzU1MTIyNDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="超平面距离"></li><li>67、CNN常用的几个模型 <img src="https://img-blog.csdn.net/20171214141903341?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzU1MTIyNDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="CNN模型"></li><li>68、带核函数的SVM为什么能分类非线性问题？ <ul><li>核函数的本质就是两个函数的内积，而这个函数在svm中可以表示成对输入值的高维映射。注意核并不是直接对应映射，核只不过是一个内积。（感觉答非所问）</li></ul></li><li>69、常用核函数即核函数条件 <ul><li>核函数选择的时候应该从线性核开始，而且在特征很多的情况下没有必要选择高斯核，应该从简单到难的选择模型。我们通常说的核函数指的是正定和函数，其充要条件是对于任意的x属于X，要求K对应的Gram矩阵要是半正定矩阵。 RBF核径向基，这类函数取值依赖于特定点间的距离，所以拉普拉斯核其实也是径向基核。 线性核：主要用于线性可分的情况 多项式核</li></ul></li><li>70、逻辑回归相关问题 <ul><li>公式一定会推</li><li>LR基本概念，最好从广义线性模型的角度分析，逻辑回归是假设y服从Bernoulli分布。</li><li>L1、L2范式</li><li>LR与SVM的比较</li><li>LR与随机森林的比较</li><li>常用优化方法</li></ul></li><li>71、什么是共线性，跟过拟合有什么联系？ <ul><li>共线性：多变量线性回归中，变量之间由于存在高度相关关系而使回归估计不准确。 共线性会造成冗余，导致过拟合。</li><li>解决方法：排除变量的相关性或加入权重正则。</li></ul></li><li>72、机器学习中的正负样本 <ul><li>在分类问题中，这个问题相对好理解一点，比如人脸识别中的例子，正样本很好理解，就是人脸的图片，负样本的选取就与问题场景相关，具体而言，如果你要进行教室中学生的人脸识别，那么负样本就是教室的窗子、墙等等，也就是说，不能是与你要研究的问题毫不相关的乱七八糟的场景图片，这样的负样本并没有意义。负样本可以根据背景生成，有时候不需要寻找额外的负样本。一般3000-10000的正样本需要5，000,000-100,000,000的负样本来学习，在互金领域一般在入模前将正负比例通过采样的方法调整到3:1-5:1。</li></ul></li><li>73、对于维度极低的特征，选择线性还是非线性分类器？ <ul><li>非线性分类器，低维空间可能很多特征都跑到一起了，导致线性不可分。 <ul><li>1.如果特征的数量很大，跟样本数量差不多，这时候选用LR或者是Linear Kernel的SVM。</li><li>2.如果特征的数量比较小，样本数量一般，不算大也不算小，选用SVM+Gaussian Kernel。</li><li>3.如果特征的数量比较小，而样本数量很多，需要手工添加一些特征变成第一种情况。</li></ul></li></ul></li><li>74、SVM、LR和决策树的对比 <ul><li>模型复杂度：SVM支持核函数，可处理线性非线性问题;LR模型简单，训练速度快，适合处理线性问题;决策树容易过拟合，需要进行剪枝。</li><li>损失函数：SVM hinge loss; LR L2正则化; Adaboost 指数损失。</li><li>数据敏感度：SVM添加容忍度对outlier不敏感，只关心支持向量，且需要先做归一化; LR对远点敏感。</li><li>数据量：数据量大就用LR，数据量小且特征少就用SVM非线性核。</li></ul></li><li>75、简述KNN最近邻分类算法的过程？ <ul><li>1计算训练样本和测试样本中每个样本点的距离（常用距离欧氏距离、马氏距离）</li><li>2对上面所有的距离进行排序；</li><li>3选前K个最小距离的样本；</li><li>4根据这K个样本的标签进行投票，得到最后的分类类别。</li></ul></li><li>76、特征向量的归一化方法有哪些？ <ul><li>线性函数转换</li><li>对数函数转换</li><li>反余切函数转换</li><li>减去均值，除以方差</li></ul></li><li>77、优化算法及其优缺点？ <ul><li>温馨提示：在回答面试官的问题的时候，往往将问题往大的方面去回答，这样不会陷于小的技术上死磕，最后很容易把自己嗑死了。</li><li>1）随机梯度下降：优点：可以一定程度上解决局部最优解的问题 ； 缺点：收敛速度较慢</li><li>2）批量梯度下降：优点：容易陷入局部最优解 ； 缺点：收敛速度较快</li><li>3）mini_batch梯度下降：综合随机梯度下降和批量梯度下降的优缺点，提取的一个中和的方法。</li><li>4）牛顿法：牛顿法在迭代的时候，需要计算Hessian矩阵，当维度较高的时候，计算 Hessian矩阵比较困难。</li><li>5）拟牛顿法：拟牛顿法是为了改进牛顿法在迭代过程中，计算Hessian矩阵而提取的算法，它采用的方式是通过逼近Hessian的方式来进行求解。</li></ul></li></ul><blockquote><p>本文首发<a href="https://ZhaoYLong.github.io" target="_blank" rel="noopener noreferrer">YunLong-Blog<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>，题目摘自CSDN、博客园等博客平台。</p></blockquote><!--]--></div><footer class="page-meta"><div class="meta-item edit-link"><a class="external-link meta-item-label" href="https://github.com/ZhaoYLong/vuepress-starter/edit/main/articles/2018-12-25-机器学习、大数据、Python题库.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page"><!--[--><!--]--> Edit this page <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><div class="meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: 2268678583@qq.com">ZhaoYLong</span><!----><!--]--><!--]--></span></div></footer><nav class="page-nav"><p class="inner"><span class="prev"><a href="/articles/2018-12-18-Java%E9%9B%86%E5%90%88%E7%B1%BB%E5%AD%A6%E4%B9%A0.html" class="" aria-label="Java集合类学习"><!--[--><!--]--> Java集合类学习 <!--[--><!--]--></a></span><span class="next"><a href="/articles/2019-01-06-Java%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E6%A2%B3%E7%90%86.html" class="" aria-label="Java并发基础梳理"><!--[--><!--]--> Java并发基础梳理 <!--[--><!--]--></a></span></p></nav><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/assets/app.3547d211.js" defer></script>
  </body>
</html>
