import{_ as e,a as o,o as c,c as l,f as n,b as p,F as u,d as s,x as t}from"./app.3547d211.js";const r={},i=n("h1",{id:"\u524D\u8A00",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#\u524D\u8A00","aria-hidden":"true"},"#"),s(" \u524D\u8A00")],-1),k=s("NLP\uFF0C\u5373\u81EA\u7136\u8BED\u8A00\u5904\u7406\u662F\u4E00\u7EC4\u7528\u4E8E\u5904\u7406\u6587\u672C\u95EE\u9898\u7684\u6280\u672F\u3002\u8FD9\u7BC7\u535A\u5BA2\u6E90\u81EA"),m={href:"https://www.kaggle.com/c/word2vec-nlp-tutorial",target:"_blank",rel:"noopener noreferrer"},b=s("Kaggle NLP\u6559\u7A0B"),d=s("\u4EE5\u53CA"),h={href:"https://www.jianshu.com/p/d2e6568250bd",target:"_blank",rel:"noopener noreferrer"},g=s("\u7B80\u4E66\u4E0A\u5BF9Kaggle\u7684\u7FFB\u8BD1\uFF0C\u4F5C\u8005\uFF1AApacheCN_\u98DE\u9F99"),_=s("\uFF0C\u5BF9\u6B64\u8868\u793A\u611F\u8C22\uFF01"),w=n("br",null,null,-1),y=s(" \u4ECE\u6570\u636E\u52A0\u8F7D\u548C\u6E05\u7406IMDB\u7535\u5F71\u8BC4\u8BBA\u8D77\u6B65\uFF0C\u7136\u540E\u5E94\u7528\u4E00\u4E2A\u7B80\u5355\u7684\u8BCD\u888B\u6A21\u578B\uFF0C\u6765\u83B7\u53D6\u4EE4\u4EBA\u60CA\u8BB6\u7684\u51C6\u786E\u9884\u6D4B\u3002"),f=n("p",null,"\u6280\u672F\u6808\uFF1A",-1),v=n("ul",null,[n("li",null,"python"),n("li",null,"NLP\u7B97\u6CD5\u5305(nltk)"),n("li",null,"\u8BA1\u7B97\u3001\u7ED8\u56FE\u7B49\u5176\u4ED6ML\u5305")],-1),q=s("\u4E00\u4E2A\u7528Python\u5199\u7684\u5173\u4E8ENLP\u548C\u6587\u672C\u5904\u7406\u7684"),x={href:"http://www.nltk.org/book/",target:"_blank",rel:"noopener noreferrer"},L=s("\u6574\u90E8\u4E66"),N=s("\u7B2C\u4E00\u90E8\u5206\u4EE3\u7801\u4E0B\u8F7D"),P={href:"https://github.com/wendykan/DeepLearningMovies/blob/master/BagOfWords.py",target:"_blank",rel:"noopener noreferrer"},z=s("\u70B9\u51FB\u4E0B\u8F7D"),B=t(`<h1 id="\u8BFB\u53D6\u6570\u636E" tabindex="-1"><a class="header-anchor" href="#\u8BFB\u53D6\u6570\u636E" aria-hidden="true">#</a> \u8BFB\u53D6\u6570\u636E</h1><p>\u7B2C\u4E00\u4E2A\u6587\u4EF6\u662F<code>py unlabeledTrainData </code>\uFF0C\u5176\u4E2D\u5305\u542B25000\u4E2AIMDB\u7535\u5F71\u8BC4\u4EF7\uFF0C\u6BCF\u4E2A\u8BC4\u4EF7\u90FD\u5E26\u6709\u6B63\u9762\u6216\u8D1F\u9762\u60C5\u611F\u6807\u7B7E\u3002</p><p>\u63A5\u7740\uFF0C\u5C06\u5236\u8868\u7B26\u5206\u9694\u6587\u4EF6\u8BFB\u5165Python\uFF0C\u4F7F\u7528pandas\u4E2D\u7684read_csv\u51FD\u6570\uFF1A</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
train <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">&quot;labeledTrainData.tsv&quot;</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">&quot;\\t&quot;</span><span class="token punctuation">,</span> quting<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token comment"># header=0\u8868\u793A\u6587\u4EF6\u7684\u7B2C\u4E00\u884C\u5305\u542B\u5217\u540D\uFF0Cdelimiter=\\t\u8868\u793A\u5B57\u6BB5\u7531\u5236\u8868\u7B26\u5206\u9694\uFF0Cquting=3\u8BA9Python\u5FFD\u7565\u53CC\u5F15\u53F7</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>\u786E\u4FDD\u8BFB\u53D625000\u884C\u548C3\u5217\uFF0C\u5982\u4E0B\u6240\u793A\uFF1A</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code>train<span class="token punctuation">.</span>shape
<span class="token punctuation">(</span><span class="token number">25000</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

train<span class="token punctuation">.</span>columns<span class="token punctuation">.</span>values
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">id</span><span class="token punctuation">,</span> sentiment<span class="token punctuation">,</span> review<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token builtin">object</span><span class="token punctuation">)</span>
<span class="token comment"># \u8BF4\u660E\u5DF2\u7ECF\u8BFB\u53D6\u5230\u8BAD\u7EC3\u96C6</span>

<span class="token comment"># \u67E5\u770B\u51E0\u6761\u8BC4\u8BBA</span>
<span class="token keyword">print</span> train<span class="token punctuation">[</span><span class="token string">&quot;review&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>\u6587\u672C\u53EF\u80FD\u5B58\u5728HTML\u6807\u7B7E\uFF0C\u8981\u4F7F\u7528\u5DE5\u5177\u5C06\u4E4B\u5220\u9664</p><h1 id="\u6570\u636E\u6E05\u7406\u548C\u6587\u672C\u9884\u5904\u7406" tabindex="-1"><a class="header-anchor" href="#\u6570\u636E\u6E05\u7406\u548C\u6587\u672C\u9884\u5904\u7406" aria-hidden="true">#</a> \u6570\u636E\u6E05\u7406\u548C\u6587\u672C\u9884\u5904\u7406</h1><p>\u5220\u9664HTML\u6807\u8BB0\uFF1ABeautifulSoup\u5305</p><p>\u5982\u679C\u6CA1\u6709\u5B89\u88C5\u8FD9\u4E2A\u5305\uFF0C\u5219\u8981\u5148\u5B89\u88C5\uFF01\u7136\u540E\u4ECEpython\u4E2D\u52A0\u8F7D\u5305\u5E76\u4F7F\u7528\u5B83\u4ECE\u8BC4\u8BBA\u4E2D\u63D0\u53D6\u6587\u672C\uFF1A</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup
<span class="token comment"># Initialize the BeautifulSoup object on a single movie review     </span>
example1 <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>train<span class="token punctuation">[</span><span class="token string">&quot;review&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  

<span class="token comment"># Print the raw review and then the output of get_text(), for </span>
<span class="token comment"># comparison</span>
<span class="token keyword">print</span> train<span class="token punctuation">[</span><span class="token string">&quot;review&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span> example1<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># get_text()\u4F1A\u63D0\u4F9B\u4E0D\u5E26\u6807\u7B7E\u7684\u8BC4\u8BBA\u6587\u672C</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h2 id="\u5904\u7406\u6807\u70B9-\u6570\u5B57\u548C\u505C\u6B62\u7B26-nltk\u548C\u6B63\u5219\u8868\u8FBE\u5F0F" tabindex="-1"><a class="header-anchor" href="#\u5904\u7406\u6807\u70B9-\u6570\u5B57\u548C\u505C\u6B62\u7B26-nltk\u548C\u6B63\u5219\u8868\u8FBE\u5F0F" aria-hidden="true">#</a> \u5904\u7406\u6807\u70B9\uFF0C\u6570\u5B57\u548C\u505C\u6B62\u7B26\uFF1ANLTK\u548C\u6B63\u5219\u8868\u8FBE\u5F0F</h2>`,12),T=n("li",null,[n("p",null,'\u5728\u8003\u8651\u5982\u4F55\u6E05\u7406\u6587\u672C\u65F6\uFF0C\u6211\u4EEC\u5E94\u8BE5\u8003\u8651\u6211\u4EEC\u8BD5\u56FE\u89E3\u51B3\u7684\u6570\u636E\u95EE\u9898\u3002\u5BF9\u4E8E\u8BB8\u591A\u95EE\u9898\uFF0C\u5220\u9664\u6807\u70B9\u7B26\u53F7\u662F\u6709\u610F\u4E49\u7684\u3002\u53E6\u4E00\u65B9\u9762\uFF0C\u5728\u8FD9\u79CD\u60C5\u51B5\u4E0B\uFF0C\u6211\u4EEC\u6B63\u5728\u89E3\u51B3\u60C5\u611F\u5206\u6790\u95EE\u9898\uFF0C\u5E76\u4E14\u6709\u53EF\u80FD"!!!"\u6216\u8005"\u{1F626}"\u53EF\u4EE5\u5E26\u6709\u60C5\u611F\uFF0C\u5E94\u8BE5\u88AB\u89C6\u4E3A\u5355\u8BCD\u3002\u5728\u672C\u6559\u7A0B\u4E2D\uFF0C\u4E3A\u7B80\u5355\u8D77\u89C1\uFF0C\u6211\u4EEC\u5B8C\u5168\u5220\u9664\u4E86\u6807\u70B9\u7B26\u53F7\uFF0C\u4F46\u8FD9\u662F\u4F60\u53EF\u4EE5\u81EA\u5DF1\u73A9\u7684\u4E1C\u897F\u3002')],-1),C=n("li",null,[n("p",null,'\u4E0E\u4E4B\u76F8\u4F3C\uFF0C\u5728\u672C\u6559\u7A0B\u4E2D\u6211\u4EEC\u5C06\u5220\u9664\u6570\u5B57\uFF0C\u4F46\u8FD8\u6709\u5176\u4ED6\u65B9\u6CD5\u53EF\u4EE5\u5904\u7406\u5B83\u4EEC\uFF0C\u8FD9\u4E9B\u65B9\u6CD5\u540C\u6837\u6709\u610F\u4E49\u3002\u4F8B\u5982\uFF0C\u6211\u4EEC\u53EF\u4EE5\u5C06\u5B83\u4EEC\u89C6\u4E3A\u5355\u8BCD\uFF0C\u6216\u8005\u4F7F\u7528\u5360\u4F4D\u7B26\u5B57\u7B26\u4E32\uFF08\u4F8B\u5982"NUM"\uFF09\u66FF\u6362\u5B83\u4EEC\u3002')],-1),D=s("\u8981\u5220\u9664\u6807\u70B9\u7B26\u53F7\u548C\u6570\u5B57\uFF0C\u6211\u4EEC\u5C06\u4F7F\u7528\u4E00\u4E2A\u5305\u6765\u5904\u7406\u6B63\u5219\u8868\u8FBE\u5F0F\uFF0C\u79F0\u4E3Are\u3002Python \u5185\u7F6E\u4E86\u8BE5\u8F6F\u4EF6\u5305\uFF1B\u65E0\u9700\u5B89\u88C5\u4EFB\u4F55\u4E1C\u897F\u3002\u5BF9\u4E8E\u6B63\u5219\u8868\u8FBE\u5F0F\u5982\u4F55\u5DE5\u4F5C\u7684\u8BE6\u7EC6\u8BF4\u660E\uFF0C\u8BF7\u53C2\u9605"),M={href:"https://docs.python.org/2/library/re.html#",target:"_blank",rel:"noopener noreferrer"},j=s("\u5305\u6587\u6863"),S=s("\u3002\u73B0\u5728\uFF0C\u5C1D\u8BD5\u4EE5\u4E0B\u65B9\u6CD5\uFF1A"),V=t(`<div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> re
<span class="token comment"># \u4F7F\u7528\u6B63\u5219\u8868\u8FBE\u5F0F\u6267\u884C\u67E5\u627E\u548C\u66FF\u6362</span>
letters_only <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">&quot;[^a-zA-Z]&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot; &quot;</span><span class="token punctuation">,</span> example1<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span> letters_only
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>\u63A5\u7740\uFF0C\u5C06\u8BC4\u8BBA\u8F6C\u6362\u4E3A\u5C0F\u5199\u5E76\u5C06\u5B83\u4EEC\u5206\u6210\u5355\u8BCD\uFF08NLP\u672F\u8BED\u4E2D\u79F0\u4E3A\u201C\u5206\u8BCD\u201D\uFF09\uFF1A</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code>lower_case <span class="token operator">=</span> letters_only<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># \u8F6C\u6362\u4E3A\u5C0F\u5199</span>
words <span class="token operator">=</span> lower_case<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>               <span class="token comment"># \u5206\u5272\u4E3A\u5355\u8BCD</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>\u6700\u540E\uFF0C\u5904\u7406\u505C\u6B62\u8BCD\uFF08\u8BF8\u5982\uFF1Aa, and, is, the\u7B49\uFF09\u3002Python\u5305\u4E2D\u5185\u7F6E\u4E86\u505C\u6B62\u8BCD\u5217\u8868\u3002\u4ECENLTK\u4E2D\u5BFC\u5165\u505C\u6B62\u8BCD\u5217\u8868\uFF1A</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token comment"># \u5982\u679C\u6CA1\u6709\u5B89\u88C5nltk\uFF0C\u8BF7\u5148\u5B89\u88C5</span>
<span class="token keyword">import</span> nltk
nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># \u4E0B\u8F7D\u6587\u672C\u6570\u636E\u96C6\uFF0C\u5305\u542B\u505C\u6B62\u8BCD</span>

<span class="token comment"># \u4F7F\u7528nltk\u83B7\u53D6\u505C\u6B62\u8BCD\u5217\u8868</span>
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> stopwords
<span class="token keyword">print</span> stopwords<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token string">&quot;english&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># \u4ECE\u201Cwords\u201D\u4E2D\u79FB\u9664\u505C\u6B62\u8BCD</span>
words <span class="token operator">=</span> <span class="token punctuation">[</span>w <span class="token keyword">for</span> w <span class="token keyword">in</span> words <span class="token keyword">if</span> <span class="token keyword">not</span> w stopwords<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token string">&quot;english&quot;</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token keyword">print</span> words

<span class="token comment"># \u5B8C\u6210\u6240\u6709\u6B65\u9AA4\u540E\uFF0C\u5F97\u5230</span>
<span class="token punctuation">[</span><span class="token string">u&#39;stuff&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;going&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;moment&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;mj&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;ve&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;started&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;listening&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;music&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;watching&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;odd&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;documentary&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;watched&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;wiz&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;watched&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;moonwalker&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;maybe&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;want&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;get&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;certain&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;insight&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;guy&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;thought&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;really&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;cool&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;eighties&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;maybe&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;make&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;mind&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;whether&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;guilty&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;innocent&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;moonwalker&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;part&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;biography&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;part&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;feature&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;film&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;remember&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;going&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;see&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;cinema&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;originally&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;released&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;subtle&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;messages&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;mj&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;feeling&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;towards&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;press&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;also&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;obvious&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;message&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;drugs&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;bad&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;m&#39;</span><span class="token punctuation">,</span> <span class="token string">u&#39;kay&#39;</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>\u6211\u4EEC\u8FD8\u53EF\u4EE5\u5BF9\u6570\u636E\u505A\u5F88\u591A\u5176\u4ED6\u64CD\u4F5C\uFF0C\u5982porter stemming(\u8BCD\u5E72\u63D0\u53D6)\u548CLemmatizing(\u8BCD\u5F62\u8FD8\u539F)\u7B49\u3002\u90FD\u5728NLTK\u5305\u4E2D\u63D0\u4F9B\u3002</p><h2 id="\u4E3A\u4E86\u4F7F\u4EE3\u7801\u53EF\u4EE5\u91CD\u7528-\u521B\u5EFA\u4E00\u4E2A\u53EF\u4EE5\u91CD\u590D\u4F7F\u7528\u7684\u51FD\u6570" tabindex="-1"><a class="header-anchor" href="#\u4E3A\u4E86\u4F7F\u4EE3\u7801\u53EF\u4EE5\u91CD\u7528-\u521B\u5EFA\u4E00\u4E2A\u53EF\u4EE5\u91CD\u590D\u4F7F\u7528\u7684\u51FD\u6570" aria-hidden="true">#</a> \u4E3A\u4E86\u4F7F\u4EE3\u7801\u53EF\u4EE5\u91CD\u7528\uFF0C\u521B\u5EFA\u4E00\u4E2A\u53EF\u4EE5\u91CD\u590D\u4F7F\u7528\u7684\u51FD\u6570</h2><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">review_to_words</span><span class="token punctuation">(</span>raw_review<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># \u5C06\u539F\u59CB\u8BC4\u8BBA\u8F6C\u6362\u4E3A\u5355\u8BCD\u5B57\u7B26\u4E32\u7684\u51FD\u6570</span>
    <span class="token comment"># \u8F93\u5165\u662F\u5355\u4E2A\u5B57\u7B26\u4E32\uFF08\u539F\u59CB\u7535\u5F71\u8BC4\u8BBA\uFF09\uFF0C</span>
    <span class="token comment"># \u8F93\u51FA\u662F\u5355\u4E2A\u5B57\u7B26\u4E32\uFF08\u9884\u5904\u7406\u8FC7\u7684\u7535\u5F71\u8BC4\u8BBA\uFF09</span>
    <span class="token comment"># 1. \u79FB\u9664 HTML</span>
    review_text <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>raw_review<span class="token punctuation">)</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span> 
    <span class="token comment">#</span>
    <span class="token comment"># 2. \u79FB\u9664\u975E\u5B57\u6BCD        </span>
    letters_only <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">&quot;[^a-zA-Z]&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot; &quot;</span><span class="token punctuation">,</span> review_text<span class="token punctuation">)</span> 
    <span class="token comment">#</span>
    <span class="token comment"># 3. \u8F6C\u6362\u4E3A\u5C0F\u5199\uFF0C\u5206\u6210\u5355\u4E2A\u5355\u8BCD</span>
    words <span class="token operator">=</span> letters_only<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>                             
    <span class="token comment">#</span>
    <span class="token comment"># 4. \u5728Python\u4E2D\uFF0C\u641C\u7D22\u96C6\u5408\u6BD4\u641C\u7D22\u5217\u8868\u5FEB\u5F97\u591A\uFF0C</span>
    <span class="token comment">#    \u6240\u4EE5\u5C06\u505C\u6B62\u8BCD\u8F6C\u6362\u4E3A\u4E00\u4E2A\u96C6\u5408</span>
    stops <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>stopwords<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token string">&quot;english&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                  
    <span class="token comment"># </span>
    <span class="token comment"># 5. \u5220\u9664\u505C\u6B62\u8BCD</span>
    meaningful_words <span class="token operator">=</span> <span class="token punctuation">[</span>w <span class="token keyword">for</span> w <span class="token keyword">in</span> words <span class="token keyword">if</span> <span class="token keyword">not</span> w <span class="token keyword">in</span> stops<span class="token punctuation">]</span>   
    <span class="token comment">#</span>
    <span class="token comment"># 6. \u5C06\u5355\u8BCD\u8FDE\u63A5\u6210\u7531\u7A7A\u683C\u5206\u9694\u7684\u5B57\u7B26\u4E32\uFF0C</span>
    <span class="token comment">#    \u5E76\u8FD4\u56DE\u7ED3\u679C\u3002</span>
    <span class="token keyword">return</span><span class="token punctuation">(</span> <span class="token string">&quot; &quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span> meaningful_words <span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br></div></div><p>\u8FD9\u91CC\u6709\u4E24\u4E2A\u65B0\u5143\u7D20\uFF1A\u9996\u5148\uFF0C\u6211\u4EEC\u5C06\u505C\u6B62\u8BCD\u5217\u8868\u8F6C\u6362\u4E3A\u4E0D\u540C\u7684\u6570\u636E\u7C7B\u578B\uFF0C\u5373\u96C6\u5408\u3002 \u8FD9\u662F\u4E3A\u4E86\u901F\u5EA6\uFF1B\u56E0\u4E3A\u6211\u4EEC\u5C06\u8C03\u7528\u8FD9\u4E2A\u51FD\u6570\u6570\u4E07\u6B21\uFF0C\u6240\u4EE5\u5B83\u9700\u8981\u5F88\u5FEB\uFF0C\u800C Python \u4E2D\u7684\u641C\u7D22\u96C6\u5408\u6BD4\u641C\u7D22\u5217\u8868\u8981\u5FEB\u5F97\u591A\u3002</p><h1 id="\u4ECE\u8BCD\u888B\u521B\u5EFA\u7279\u5F81-\u4F7F\u7528sklearn" tabindex="-1"><a class="header-anchor" href="#\u4ECE\u8BCD\u888B\u521B\u5EFA\u7279\u5F81-\u4F7F\u7528sklearn" aria-hidden="true">#</a> \u4ECE\u8BCD\u888B\u521B\u5EFA\u7279\u5F81\uFF08\u4F7F\u7528sklearn\uFF09</h1><p>\u73B0\u5728\u6211\u4EEC\u5DF2\u7ECF\u6574\u7406\u4E86\u6211\u4EEC\u7684\u8BAD\u7EC3\u8BC4\u8BBA\uFF0C\u6211\u4EEC\u5982\u4F55\u5C06\u5B83\u4EEC\u8F6C\u6362\u4E3A\u673A\u5668\u5B66\u4E60\u7684\u67D0\u79CD\u6570\u5B57\u8868\u793A\uFF1F\u4E00\u79CD\u5E38\u89C1\u7684\u65B9\u6CD5\u53EB\u505A\u8BCD\u888B\u3002\u8BCD\u888B\u6A21\u578B\u4ECE\u6240\u6709\u6587\u6863\u4E2D\u5B66\u4E60\u8BCD\u6C47\u8868\uFF0C\u7136\u540E\u901A\u8FC7\u8BA1\u7B97\u6BCF\u4E2A\u5355\u8BCD\u51FA\u73B0\u7684\u6B21\u6570\u5BF9\u6BCF\u4E2A\u6587\u6863\u8FDB\u884C\u5EFA\u6A21\u3002\u4F8B\u5982\uFF0C\u8003\u8651\u4EE5\u4E0B\u4E24\u53E5\u8BDD\uFF1A</p><p>\u53E5\u5B501: &quot;The cat sat on the hat&quot;</p><p>\u53E5\u5B502: &quot;The dog ate the cat and the hat&quot;</p><p>\u4ECE\u8FD9\u4E24\u4E2A\u53E5\u5B50\u4E2D\uFF0C\u6211\u4EEC\u7684\u8BCD\u6C47\u5982\u4E0B\uFF1A</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token punctuation">{</span>the<span class="token punctuation">,</span> cat<span class="token punctuation">,</span> sat<span class="token punctuation">,</span> on<span class="token punctuation">,</span> hat<span class="token punctuation">,</span> dog<span class="token punctuation">,</span> ate<span class="token punctuation">,</span> <span class="token keyword">and</span><span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>\u4E3A\u4E86\u5F97\u5230\u6211\u4EEC\u7684\u8BCD\u888B\uFF0C\u6211\u4EEC\u8BA1\u7B97\u6BCF\u4E2A\u5355\u8BCD\u51FA\u73B0\u5728\u6BCF\u4E2A\u53E5\u5B50\u4E2D\u7684\u6B21\u6570\u3002\u5728\u53E5\u5B50 1 \u4E2D\uFF0C\u201Cthe\u201D\u51FA\u73B0\u4E24\u6B21\uFF0C\u201Ccat\u201D\uFF0C\u201Csat\u201D\uFF0C\u201Con\u201D\u548C\u201Chat\u201D\u6BCF\u6B21\u51FA\u73B0\u4E00\u6B21\uFF0C\u56E0\u6B64\u53E5\u5B50 1 \u7684\u7279\u5F81\u5411\u91CF\u662F\uFF1A</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token punctuation">{</span>the<span class="token punctuation">,</span> cat<span class="token punctuation">,</span> sat<span class="token punctuation">,</span> on<span class="token punctuation">,</span> hat<span class="token punctuation">,</span> dog<span class="token punctuation">,</span> ate<span class="token punctuation">,</span> <span class="token keyword">and</span><span class="token punctuation">}</span>

<span class="token comment">#\u53E5\u5B501\u7279\u5F81:</span>
<span class="token punctuation">{</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">}</span>
<span class="token comment">#\u53E5\u5B502\u7279\u5F81:</span>
<span class="token punctuation">{</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>\u5728 IMDB \u6570\u636E\u4E2D\uFF0C\u6211\u4EEC\u6709\u5927\u91CF\u7684\u8BC4\u8BBA\uFF0C\u8FD9\u5C06\u4E3A\u6211\u4EEC\u63D0\u4F9B\u5927\u91CF\u7684\u8BCD\u6C47\u3002\u8981\u9650\u5236\u7279\u5F81\u5411\u91CF\u7684\u5927\u5C0F\uFF0C\u6211\u4EEC\u5E94\u8BE5\u9009\u62E9\u6700\u5927\u8BCD\u6C47\u91CF\u3002\u4E0B\u9762\uFF0C\u6211\u4EEC\u4F7F\u7528 5000 \u4E2A\u6700\u5E38\u7528\u7684\u5355\u8BCD\uFF08\u8BB0\u4F4F\u5DF2\u7ECF\u5220\u9664\u4E86\u505C\u6B62\u8BCD\uFF09\u3002</p><p>\u4F7F\u7528scikit-learn\u4E2D\u7684feature_extraction\u6A21\u5757\u6765\u521B\u5EFA\u8BCD\u888B\u7279\u5F81\u3002</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token keyword">print</span> <span class="token string">&quot;Creating the bag of words...\\n&quot;</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer

<span class="token comment"># \u521D\u59CB\u5316 &quot;CountVectorizer&quot; \u5BF9\u8C61\uFF0C</span>
<span class="token comment"># \u8FD9\u662F scikit-learn \u7684\u4E00\u4E2A\u8BCD\u888B\u5DE5\u5177\u3002</span>
vectorizer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span>analyzer <span class="token operator">=</span> <span class="token string">&quot;word&quot;</span><span class="token punctuation">,</span>   \\
                             tokenizer <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>    \\
                             preprocessor <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> \\
                             stop_words <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>   \\
                             max_features <span class="token operator">=</span> <span class="token number">5000</span><span class="token punctuation">)</span> 

<span class="token comment"># fit_transform() \u6709\u4E24\u4E2A\u529F\u80FD\uFF1A</span>
<span class="token comment"># \u9996\u5148\uFF0C\u5B83\u62DF\u5408\u6A21\u578B\u5E76\u5B66\u4E60\u8BCD\u6C47\uFF1B</span>
<span class="token comment"># \u7B2C\u4E8C\uFF0C\u5B83\u5C06\u6211\u4EEC\u7684\u8BAD\u7EC3\u6570\u636E\u8F6C\u6362\u4E3A\u7279\u5F81\u5411\u91CF\u3002</span>
<span class="token comment"># fit_transform \u7684\u8F93\u5165\u5E94\u8BE5\u662F\u5B57\u7B26\u4E32\u5217\u8868\u3002</span>
train_data_features <span class="token operator">=</span> vectorizer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>clean_train_reviews<span class="token punctuation">)</span>

<span class="token comment"># Numpy \u6570\u7EC4\u5F88\u5BB9\u6613\u4F7F\u7528\uFF0C\u56E0\u6B64\u5C06\u7ED3\u679C\u8F6C\u6362\u4E3A\u6570\u7EC4</span>
train_data_features <span class="token operator">=</span> train_data_features<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># \u67E5\u770B\u8BAD\u7EC3\u6570\u636E\u6570\u7EC4\u73B0\u5728\u7684\u6837\u5B50\uFF1A</span>
<span class="token keyword">print</span> train_data_features<span class="token punctuation">.</span>shape
<span class="token punctuation">(</span><span class="token number">25000</span><span class="token punctuation">,</span> <span class="token number">5000</span><span class="token punctuation">)</span> <span class="token comment"># \u5B83\u6709 25,000 \u884C\u548C 5,000 \u4E2A\u7279\u5F81\uFF08\u6BCF\u4E2A\u8BCD\u6C47\u4E00\u4E2A\uFF09\u3002</span>

<span class="token comment"># \u8BCD\u888B\u6A21\u578B\u8BAD\u7EC3\u5B8C\u6210\uFF0C\u770B\u770B\u8BCD\u6C47\u8868\uFF1A</span>
vocab <span class="token operator">=</span> vectorizer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> vocab

</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><h1 id="\u968F\u673A\u68EE\u6797" tabindex="-1"><a class="header-anchor" href="#\u968F\u673A\u68EE\u6797" aria-hidden="true">#</a> \u968F\u673A\u68EE\u6797</h1><p>\u5230\u4E86\u8FD9\u91CC\uFF0C\u6211\u4EEC\u6709\u8BCD\u888B\u7684\u6570\u5B57\u8BAD\u7EC3\u7279\u5F81\u548C\u6BCF\u4E2A\u7279\u5F81\u5411\u91CF\u7684\u539F\u59CB\u60C5\u611F\u6807\u7B7E\uFF0C\u6240\u4EE5\u8BA9\u6211\u4EEC\u505A\u4E00\u4E9B\u76D1\u7763\u5B66\u4E60\uFF01</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token keyword">print</span> <span class="token string">&quot;Training the random forest...&quot;</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier

<span class="token comment"># \u4F7F\u7528 100 \u68F5\u6811\u521D\u59CB\u5316\u968F\u673A\u68EE\u6797\u5206\u7C7B\u5668</span>
forest <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>n_estimators <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">)</span> 

<span class="token comment"># \u4F7F\u7528\u8BCD\u888B\u4F5C\u4E3A\u7279\u5F81\u5E76\u5C06\u60C5\u611F\u6807\u7B7E\u4F5C\u4E3A\u54CD\u5E94\u53D8\u91CF\uFF0C\u4F7F\u68EE\u6797\u62DF\u5408\u8BAD\u7EC3\u96C6</span>
<span class="token comment"># \u8FD9\u53EF\u80FD\u9700\u8981\u51E0\u5206\u949F\u6765\u8FD0\u884C</span>
forest <span class="token operator">=</span> forest<span class="token punctuation">.</span>fit<span class="token punctuation">(</span> train_data_features<span class="token punctuation">,</span> train<span class="token punctuation">[</span><span class="token string">&quot;sentiment&quot;</span><span class="token punctuation">]</span> <span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><h1 id="\u521B\u5EFA\u63D0\u4EA4" tabindex="-1"><a class="header-anchor" href="#\u521B\u5EFA\u63D0\u4EA4" aria-hidden="true">#</a> \u521B\u5EFA\u63D0\u4EA4</h1><p>\u5269\u4E0B\u7684\u5C31\u662F\u5728\u6211\u4EEC\u7684\u6D4B\u8BD5\u96C6\u4E0A\u8FD0\u884C\u8BAD\u7EC3\u597D\u7684\u968F\u673A\u68EE\u6797\u5E76\u521B\u5EFA\u4E00\u4E2A\u63D0\u4EA4\u6587\u4EF6\u3002 \u5982\u679C\u4F60\u8FD8\u6CA1\u6709\u8FD9\u6837\u505A\uFF0C\u8BF7\u4ECE\u201C\u6570\u636E\u201D\u9875\u9762\u4E0B\u8F7DtestData.tsv\u3002 \u6B64\u6587\u4EF6\u5305\u542B\u53E6\u5916 25,000 \u6761\u8BC4\u8BBA\u548C\u6807\u7B7E\uFF1B\u6211\u4EEC\u7684\u4EFB\u52A1\u662F\u9884\u6D4B\u60C5\u611F\u6807\u7B7E\u3002</p><p>\u8BF7\u6CE8\u610F\uFF0C\u5F53\u6211\u4EEC\u4F7F\u7528\u8BCD\u888B\u4F5C\u4E3A\u6D4B\u8BD5\u96C6\u65F6\uFF0C\u6211\u4EEC\u53EA\u8C03\u7528transform\uFF0C\u800C\u4E0D\u662F\u50CF\u8BAD\u7EC3\u96C6\u90A3\u6837\u8C03\u7528fit_transform\u3002 \u5728\u673A\u5668\u5B66\u4E60\u4E2D\uFF0C\u4F60\u4E0D\u5E94\u8BE5\u4F7F\u7528\u6D4B\u8BD5\u96C6\u6765\u62DF\u5408\u4F60\u7684\u6A21\u578B\uFF0C\u5426\u5219\u4F60\u5C06\u9762\u4E34\u8FC7\u62DF\u5408\u7684\u98CE\u9669\u3002 \u51FA\u4E8E\u8FD9\u4E2A\u539F\u56E0\uFF0C\u6211\u4EEC\u5C06\u6D4B\u8BD5\u96C6\u4FDD\u6301\u5728\u7981\u6B62\u72B6\u6001\uFF0C\u76F4\u5230\u6211\u4EEC\u51C6\u5907\u597D\u8FDB\u884C\u9884\u6D4B\u3002</p><div class="language-python ext-py line-numbers-mode"><pre class="language-python"><code><span class="token comment"># \u8BFB\u53D6\u6D4B\u8BD5\u6570\u636E</span>
test <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">&quot;testData.tsv&quot;</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">&quot;\\t&quot;</span><span class="token punctuation">,</span> \\
                   quoting<span class="token operator">=</span><span class="token number">3</span> <span class="token punctuation">)</span>

<span class="token comment"># \u9A8C\u8BC1\u6709 25,000 \u884C\u548C 2 \u5217</span>
<span class="token keyword">print</span> test<span class="token punctuation">.</span>shape

<span class="token comment"># \u521B\u5EFA\u4E00\u4E2A\u7A7A\u5217\u8868\u5E76\u9010\u4E2A\u9644\u52A0\u5E72\u51C0\u7684\u8BC4\u8BBA</span>
num_reviews <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test<span class="token punctuation">[</span><span class="token string">&quot;review&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
clean_test_reviews <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> 

<span class="token keyword">print</span> <span class="token string">&quot;Cleaning and parsing the test set movie reviews...\\n&quot;</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">xrange</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>num_reviews<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span> <span class="token string">&quot;Review %d of %d\\n&quot;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> num_reviews<span class="token punctuation">)</span>
    clean_review <span class="token operator">=</span> review_to_words<span class="token punctuation">(</span> test<span class="token punctuation">[</span><span class="token string">&quot;review&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token punctuation">)</span>
    clean_test_reviews<span class="token punctuation">.</span>append<span class="token punctuation">(</span> clean_review <span class="token punctuation">)</span>

<span class="token comment"># \u83B7\u53D6\u6D4B\u8BD5\u96C6\u7684\u8BCD\u888B\uFF0C\u5E76\u8F6C\u6362\u4E3A numpy \u6570\u7EC4</span>
test_data_features <span class="token operator">=</span> vectorizer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>clean_test_reviews<span class="token punctuation">)</span>
test_data_features <span class="token operator">=</span> test_data_features<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># \u4F7F\u7528\u968F\u673A\u68EE\u6797\u8FDB\u884C\u60C5\u611F\u6807\u7B7E\u9884\u6D4B</span>
result <span class="token operator">=</span> forest<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_data_features<span class="token punctuation">)</span>

<span class="token comment"># \u5C06\u7ED3\u679C\u590D\u5236\u5230\u5E26\u6709 &quot;id&quot; \u5217\u548C &quot;sentiment&quot; \u5217\u7684 pandas dataframe</span>
output <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span> data<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">&quot;id&quot;</span><span class="token punctuation">:</span>test<span class="token punctuation">[</span><span class="token string">&quot;id&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">&quot;sentiment&quot;</span><span class="token punctuation">:</span>result<span class="token punctuation">}</span> <span class="token punctuation">)</span>

<span class="token comment"># \u4F7F\u7528 pandas \u7F16\u5199\u9017\u53F7\u5206\u9694\u7684\u8F93\u51FA\u6587\u4EF6</span>
output<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span> <span class="token string">&quot;Bag_of_Words_model.csv&quot;</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> quoting<span class="token operator">=</span><span class="token number">3</span> <span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><p>\u606D\u559C\uFF0C\u4F60\u5DF2\u51C6\u5907\u597D\u7B2C\u4E00\u6B21\u63D0\u4EA4\uFF01 \u5C1D\u8BD5\u4E0D\u540C\u7684\u4E8B\u60C5\uFF0C\u770B\u770B\u4F60\u7684\u7ED3\u679C\u5982\u4F55\u53D8\u5316\u3002 \u4F60\u53EF\u4EE5\u4EE5\u4E0D\u540C\u65B9\u5F0F\u6E05\u7406\u8BC4\u8BBA\uFF0C\u4E3A\u8BCD\u888B\u8868\u793A\u9009\u62E9\u4E0D\u540C\u6570\u91CF\u7684\u8BCD\u6C47\u8868\u5355\u8BCD\uFF0C\u5C1D\u8BD5 Porter Stemming\uFF0C\u4E0D\u540C\u7684\u5206\u7C7B\u5668\u6216\u4EFB\u4F55\u5176\u4ED6\u7684\u4E1C\u897F\u3002 \u8981\u5728\u4E0D\u540C\u7684\u6570\u636E\u96C6\u4E0A\u8BD5\u7528\u4F60\u7684 NLP \u62DB\u5F0F\uFF0C\u4F60\u8FD8\u53EF\u4EE5\u53C2\u52A0\u6211\u4EEC\u7684\u70C2\u756A\u8304\u6BD4\u8D5B\u3002 \u6216\u8005\uFF0C\u5982\u679C\u4F60\u4E3A\u5B8C\u5168\u4E0D\u540C\u7684\u4E1C\u897F\u505A\u597D\u4E86\u51C6\u5907\uFF0C\u8BF7\u8BBF\u95EE\u6DF1\u5EA6\u5B66\u4E60\u548C\u8BCD\u5411\u91CF\u9875\u9762\u3002</p>`,28),F=s("\u5B66\u4E60\u6E90"),I={href:"https://www.jianshu.com/p/d2e6568250bd",target:"_blank",rel:"noopener noreferrer"},A=s("\u7B80\u4E66"),K=s("\uFF0C\u63D0\u51FA\u611F\u8C22\uFF01"),E=n("h1",{id:"\u4F7F\u7528nlp\u521B\u5EFAtwitter\u8BC4\u4EF7\u5206\u7C7B\u5668\u7684\u60F3\u6CD5",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#\u4F7F\u7528nlp\u521B\u5EFAtwitter\u8BC4\u4EF7\u5206\u7C7B\u5668\u7684\u60F3\u6CD5","aria-hidden":"true"},"#"),s(" \u4F7F\u7528NLP\u521B\u5EFATwitter\u8BC4\u4EF7\u5206\u7C7B\u5668\u7684\u60F3\u6CD5")],-1),H=n("ul",null,[n("li",null,"\u53D6\u4EE3\u4EBA\u5DE5\u6253\u6807\u6CE8\u7684\u8FC7\u7A0B\uFF0C\u63D0\u9AD8\u6570\u636E\u5206\u6790\u3001\u6316\u6398\u6548\u7387")],-1),R=n("h3",{id:"\u6982\u8FF0",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#\u6982\u8FF0","aria-hidden":"true"},"#"),s(" \u6982\u8FF0")],-1),Z=n("p",null,"\u53C2\u7167\u4E4B\u524D\u7684\u81EA\u7136\u8BED\u8A00\u7B97\u6CD5\u7814\u7A76\u535A\u5BA2\uFF0C\u5F97\u77E5\u5904\u7406\u63A8\u6587\u662F\u53EF\u884C\u7684\uFF0C\u91CD\u70B9\u662F\u5982\u4F55\u5408\u7406\u7684\u5206\u51FA\u63A8\u6587\u4E2D\u7684\u611F\u60C5\u8272\u5F69\u548C\u4F7F\u7528\u54EA\u79CD\u5206\u7C7B\u7B97\u6CD5\u6765\u5904\u7406\uFF01\u82E5\u7814\u7A76\u51FA\u7ED3\u679C\u53EF\u7528\u4E8E\u5C0F\u89C4\u6A21\u7684\u8206\u60C5\u5206\u6790\u6709\u4E00\u5B9A\u7684\u4EF7\u503C\u3002",-1),W=n("p",null,"\u8FD9\u4E2A\u60F3\u6CD5\u4EA7\u751F\u4E8E\u5357\u4EAC\u9762\u8BD5\u30105\u670813\u53F7\u3011\u4E4B\u540E\uFF01\u76EE\u524D\u89C9\u5F97\u53EF\u884C\uFF01\u505A\u8FD9\u65B9\u9762\u5DE5\u4F5C\u7684\u7814\u7A76\u4EBA\u5458\u4E5F\u5F88\u591A\uFF0C\u6211\u53EA\u662F\u4E2A\u521D\u5B66\u8005\uFF01\u{1F60A}",-1),Y=n("p",null,"\u4E00\u5B9A\u4F1A\u4F7F\u7528\u5230\u673A\u5668\u5B66\u4E60\u5E93\u6216\u5305\uFF01",-1),J=n("p",null,"\u5DE5\u5177\u521D\u5B9A\uFF1AJava + NLP + classification-Alg \u6216\u8005 Python + NLP + classification-Alg",-1),O=s("\u672C\u6587\u9996\u6B21\u53D1\u5E03\u4E8E "),U={href:"http://ZhaoYLong.github.io",target:"_blank",rel:"noopener noreferrer"},G=s("YunLongBlog"),Q=s(", \u4F5C\u8005 "),X={href:"http://www.twtter.com/Laqudee1",target:"_blank",rel:"noopener noreferrer"},$=s("Laqudee"),nn=s(" ,\u8F6C\u8F7D\u8BF7\u4FDD\u7559\u539F\u6587\u94FE\u63A5.");function sn(an,pn){const a=o("ExternalLinkIcon");return c(),l(u,null,[i,n("p",null,[k,n("a",m,[b,p(a)]),d,n("a",h,[g,p(a)]),_,w,y]),f,v,n("p",null,[q,n("a",x,[L,p(a)])]),n("p",null,[N,n("a",P,[z,p(a)])]),B,n("ul",null,[T,C,n("li",null,[n("p",null,[D,n("a",M,[j,p(a)]),S])])]),V,n("blockquote",null,[n("p",null,[F,n("a",I,[A,p(a)]),K])]),E,H,R,Z,W,Y,J,n("blockquote",null,[n("p",null,[O,n("a",U,[G,p(a)]),Q,n("a",X,[$,p(a)]),nn])])],64)}var en=e(r,[["render",sn],["__file","2019-05-13-NLP\u7B97\u6CD5\u7814\u7A76(Part.1).html.vue"]]);export{en as default};
